---
title: Year-End Productivity Toolkit
description: Year-End Productivity Toolkit for 2026 optimization.
lastUpdated: 2025-12-09
sidebar:
  badge:
    text: Toolkit
    variant: tip
---

import { Steps, FileTree, Tabs, TabItem, Card, CardGrid } from '@astrojs/starlight/components';


### 1. Zero-Friction Access

#### A. SSH Keys
**Goal:** Enable password-less login to run automated scripts and transfer files seamlessly.

<Steps>

1. **Generate a Key Pair**

    Run this on your **local computer** (Terminal or PowerShell). Press `Enter` to accept defaults (file location and no passphrase).

    ```bash frame="none"
    ssh-keygen -t ed25519
    ```

2. **Copy Public Key to Cluster**

    Send your public key to the cluster. Replace `boilerid` with your actual username.

    :::tip[Duo Auth Tip]
    When prompted for your password, type your password followed by `,push` (e.g., `password,push`) to approve the Duo request.
    :::

    <Tabs>
    <TabItem label="Mac / Linux / Git Bash" icon="linux">
    ```bash frame="none"
    ssh-copy-id boilerid@bell.rcac.purdue.edu
    ```
    </TabItem>
    <TabItem label="Windows (PowerShell)" icon="seti:windows">
    ```powershell frame="none"
    type $env:USERPROFILE\.ssh\id_ed25519.pub | ssh boilerid@bell.rcac.purdue.edu "mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys"
    ```
    </TabItem>
    </Tabs>

3. **Test Connection**

    You should now be able to log in without typing a password:

    ```bash frame="none"
    ssh boilerid@bell.rcac.purdue.edu
    ```
</Steps>


#### B. SSH Configuration

**Goal:** Simplify login commands (e.g., type `ssh bell` instead of `ssh user@bell.rcac.purdue.edu`).

<Steps>

1. **Create/Edit the Config File**

    Open `~/.ssh/config` on your local computer using a text editor (VS Code, Nano, Notepad, etc.).

2. **Paste the Configuration**

    Copy the block below. Be sure to replace `boilerid` with your specific username.

    ```bash title="~/.ssh/config"
    # --- GLOBAL RCAC DEFAULTS ---
    # Applies to all RCAC clusters automatically
    Host *.rcac.purdue.edu
        User boilerid                 # <--- REPLACE THIS with your username
        IdentityFile ~/.ssh/id_ed25519
        Port 22
        ForwardAgent yes
        ForwardX11 yes
        
        # Keep connection alive to prevent timeouts
        ServerAliveInterval 300
        ServerAliveCountMax 2
        
        # Multiplexing & Persistence (Speed boost for multiple windows)
        ControlMaster auto
        ControlPath ~/.ssh/cm-%r@%h:%p
        ControlPersist 10m

    # --- CLUSTER SHORTCUTS ---

    Host bell
        HostName bell.rcac.purdue.edu

    Host negishi
        HostName negishi.rcac.purdue.edu

    Host anvil
        HostName anvil.rcac.purdue.edu
        # User x-boilerid           # Uncomment and update if Anvil username differs
    ```

3. **Usage**

    You can now connect instantly using the short names:

    ```bash frame="none"
    ssh bell
    ssh negishi
    ssh anvil
    rsync -av ~/localfolder/ bell:/depot/project/remote_folder/
    ```

</Steps>

### 2. Shell Aliases & Dotfiles

**Goal:** Save keystrokes on repetitive commands and prevent home directory quota issues.

#### A. The Setup

Instead of cluttering your main `.bashrc` file, create a separate file for shortcuts.

<Steps>

1. **Create the file:**

    ```bash frame="none"
    nano ~/.bash_aliases
    ```

2. **Paste the content below** (Customize the `APPTAINER_CACHEDIR` path!).

3. **Activate it:**

    Open your `.bashrc` (`nano ~/.bashrc`) and ensure this block exists (it usually does by default):

    ```bash fr
    if [ -f ~/.bash_aliases ]; then
        . ~/.bash_aliases
    fi
    ```

4. **Reload:**

    Run `source ~/.bashrc` to apply changes immediately.

</Steps>

#### B. Recommended Aliases

Copy this into your `~/.bash_aliases` file.

```bash title="~/.bash_aliases"
# --- 1. ENVIRONMENT VARIABLES ---
# CRITICAL: Point Apptainer cache to Depot/Scratch to avoid filling up Home
export APPTAINER_CACHEDIR="/depot/itap/$USER/apptainer"

# --- 2. LISTING & NAVIGATION ---
alias pwd='pwd -P'                # Show physical path (resolves symlinks)
alias ls='ls --color=auto -v'     # Colorized output
alias ll='ls -l'                  # Standard long list
alias la='ls -Al'                 # Show hidden files
alias lt='ls -ltr'                # Sort by date (newest at bottom) - GREAT for checking logs
alias lk='ls -lSr'                # Sort by size (biggest at bottom)
alias ld='ls -d */'               # List directories only

# Advanced Listing (Requires 'exa' if you use 'lr')
# alias lr='exa --long --color-scale --tree --level=3' 

# --- 3. DISK USAGE ---
alias du='du -kh'                 # Human readable sizes
alias dd='du -sch *'              # Summary of current directory sizes

# --- 4. SAFETY ---
alias rm='rm -i'                  # Ask before deleting
alias cp='cp -i'                  # Ask before overwriting
alias mv='mv -i'                  # Ask before overwriting

# --- 5. SLURM (JOB MANAGEMENT) ---

# Check MY jobs (Formatted for readability)
alias myq='squeue -o "%12i %20j %2t %8u %10q %10a %10P %10Q %5D %5C %11l %11L %R" -u $USER'

# Check ALL jobs
alias qs='squeue -a -o "%12i %20j %2t %8u %10q %10a %10P %10Q %5D %5C %11l %11L %R"'

# Check Node Status (Idle, Mixed, Allocated, etc.)
alias ql='sinfo -o "%20P %5D %14F %8z %10m %10d %11l %N"'

# Quick Interactive Job (Customize allocation/time as needed)
alias interact='sinteractive -A <YOUR_ALLOCATION> -t 04:00:00 -N 1 -n 16'
````

#### C. Dotfiles Management

Version control your configuration to keep clusters and local machines in sync.

<Steps>

1.  Create a **private** GitHub repository named `dotfiles`.

2.  Move your config files there and symlink them back.

    ```bash
    # Example workflow
    mkdir ~/dotfiles
    mv ~/.bash_aliases ~/dotfiles/
    ln -s ~/dotfiles/.bash_aliases ~/.bash_aliases
    ```

</Steps>


### 3. VS Code Remote SSH

**Goal:** Edit cluster files with a full graphical interface, syntax highlighting, and integrated terminals.

**Setup Steps**

<Steps>

1.  **Install:** Download [VS Code](https://code.visualstudio.com/) locally.

2.  **Extension:** Open VS Code, go to Extensions (square icon on left), and install **Remote - SSH**.

3.  **Connect:** Click the green **"\>\<"** icon (bottom-left corner) â†’ **Connect to Host...** â†’ Select `bell` (or your target cluster).

</Steps>

**Essential Extensions (Install on Remote)**
Once connected, install these in the "SSH: bell" section of your extensions pane:

<CardGrid>
<Card title="Python & Pylance" icon="seti:python">
For code completion and debugging.
</Card>
<Card title="ShellCheck" icon="linux">
To catch errors in your bash scripts automatically.
</Card>
<Card title="GitLens" icon="github">
To visualize who edited code and when.
</Card>
<Card title="R" icon="seti:r">
For R language support (requires extra config).
</Card>
</CardGrid>
**Editing Tips**

  * **Integrated Terminal:** Press `Ctrl + \`` to open a terminal. It opens automatically in your current remote folder.
  * **Consistency:** If your config uses a specific node (e.g., `bell-fe02`), stick to it. Connecting to different nodes launches multiple VS Code server instances, which wastes resources.
  * **Drag & Drop:** Drag files from your local computer into the VS Code file explorer to upload them instantly.

:::note[Reference]
ðŸ“„ **[View Quick Reference (PDF)](/assets/vscode-remote-ssh.pdf)** *Includes configurations for Jupyter Kernels and R paths.*
:::



### 4. Conda Environment Management

**Goal:** Isolate software dependencies per project and avoid "works on my machine" issues.

**Setup: Avoid Quota Issues**
Conda environments are large. Configure them to store data in your Depot space, not your Home directory (which has strict limits).

<Steps>

1.  Create the directory: `mkdir -p /depot/your_lab/user/conda_envs`

2.  Edit your config: `nano ~/.condarc`

3.  Add this text:

    ```yaml title="~/.condarc"
    envs_dirs:
      - /depot/your_lab/user/conda_envs
      - ~/.conda/envs
    pkgs_dirs:
      - /depot/your_lab/user/conda_pkgs
      - ~/.conda/pkgs
    ```

</Steps>

**Quick Commands (Use `mamba` for speed)**
The RCAC conda module includes `mamba`, which is faster than standard conda.

| Action | Command |
| :--- | :--- |
| **Start** | `module load conda` |
| **Create** | `mamba create -n my_env python=3.10` |
| **Activate** | `conda activate my_env` |
| **Install** | `mamba install bioconda::samtools` |
| **List Envs** | `conda env list` |
| **Remove** | `conda env remove -n my_env` |

**Reproducibility: The "Time Capsule"**
Before you finish a project, save a snapshot of your environment. This guarantees reproducibility.

<Steps>

1.  **Export (Save):**

    ```bash frame="none"
    # Saves only the packages you explicitly asked for (cleaner)
    conda env export --from-history > environment.yml

    # Saves EXACT versions of everything (safest for immediate reproduction)
    conda list --explicit > spec.txt
    ```

2.  **Import (Load):**

    ```bash frame="none"
    mamba env create -f environment.yml
    ```

</Steps>

ðŸ“„ **[View Quick Reference (PDF)](/assets/RCAC_conda-package-management.pdf)** *Includes visual workflows for creating vs. using environments and version pinning examples.*


## 5. Containers & Overlays

**Goal:** Use software that runs the same way everywhere, without installation headaches or file quota (inode) issues.

**Why Apptainer (Singularity)?**

  * **Speed:** A container is a single file (`.sif`). It loads faster than a Conda environment with 30,000 tiny files.
  * **Portability:** Build it on your laptop, run it on Bell, run it on Anvil. It always works.

**Quick Commands**

```bash frame="none"
# Pull a container from Docker Hub
apptainer pull fastqc.sif docker://biocontainers/fastqc:v0.11.9_cv8

# Run a tool inside the container
apptainer exec fastqc.sif fastqc input.fq

# Run on GPU (Bell/Gilbreth only)
apptainer exec --nv deepvariant.sif run_deepvariant ...
```

**The "Inode Saver" (Overlays)**

:::tip[Use Overlays for High File Counts]
Some tools (like `maker` or `trinity`) create millions of small temporary files, which hits your file count limit (quota) even if you have storage space left.

**Solution:** Create an overlay file. The tool writes its temp files *inside* this single file, hiding them from the file system.
:::

```bash frame="none"
# 1. Create a 5GB overlay file
apptainer overlay create --size 5120 my_overlay.img

# 2. Run your tool with the overlay attached
apptainer exec --overlay my_overlay.img maker.sif maker ...
```

ðŸ“„ **[View Quick Reference (PDF)](/assets/RCAC_apptainers-for-software-management.pdf)** *Includes recipes for building your own containers and advanced bind-mount usage.*



## 6. Custom Bin Directory

**Goal:** Standardize your tools and run complex commands with a single word.

**Setup**

<Steps>

1.  Create the directory: `mkdir -p ~/bin`

2.  Add to your `$PATH` (if not already there):

    ```bash frame="none"
    # Add this to your ~/.bashrc
    export PATH="$HOME/bin:$PATH"
    ```

3.  Reload: `source ~/.bashrc`

</Steps>

**Recommended Wrapper Scripts**
*Save these files in `~/bin`, then run `chmod +x ~/bin/*` to make them executable.*

<Tabs>
<TabItem label="sam2bam">
#### The "Sam to Sorted Bam" Converter
Converts SAM to BAM, sorts it, and indexes it in one go.

````
```bash frame="none" title="~/bin/sam2bam"
#!/bin/bash
# Usage: sam2bam input.sam
# Output: input.sorted.bam and input.sorted.bam.bai

if [ -z "$1" ]; then
    echo "Usage: sam2bam <input.sam>"
    exit 1
fi

BASE="${1%.sam}"
THREADS=4

echo "Converting $1 -> $BASE.sorted.bam..."

# Pipe view directly to sort to save disk I/O
samtools view -uS -@ $THREADS "$1" | \
samtools sort -@ $THREADS -o "$BASE.sorted.bam"

# Index immediately
samtools index "$BASE.sorted.bam"
echo "Done."
```
````

</TabItem>
<TabItem label="run\_bwa">
#### The BWA-MEM Wrapper
Runs BWA from a container without needing to load modules or remember the container path.

````
```bash frame="none" title="~/bin/run_bwa"
#!/bin/bash
# Usage: run_bwa <ref.fa> <read1.fq> <read2.fq>
# Output: read1.sam

CONTAINER="/depot/itap/biocontainers/bwa.sif" # Update with your path
REF=$1
R1=$2
R2=$3
THREADS=12

if [ -z "$3" ]; then
    echo "Usage: run_bwa <ref.fa> <r1.fq> <r2.fq>"
    exit 1
fi

OUTPUT="$(basename ${R1%.*}.sam)"

echo "Running BWA MEM with $THREADS threads..."
apptainer exec $CONTAINER bwa mem -t $THREADS "$REF" "$R1" "$R2" > "$OUTPUT"
```
````

</TabItem>
<TabItem label="bsort">
#### Fast BAM Sort
Quickly sort a BAM file using available threads.

````
```bash frame="none" title="~/bin/bsort"
#!/bin/bash
# Usage: bsort input.bam

if [ -z "$1" ]; then
    echo "Usage: bsort <input.bam>"
    exit 1
fi

BASE="${1%.bam}"
THREADS=8

samtools sort -@ $THREADS -o "$BASE.sorted.bam" "$1"
samtools index "$BASE.sorted.bam"
```
````

</TabItem>
<TabItem label="fqcount">
#### Read Counter
Quickly checks read counts in gzipped files (useful for verifying transfers).

````
```bash frame="none" title="~/bin/fqcount"
#!/bin/bash
# Usage: fqcount file.fastq.gz

zcat "$1" | echo "$1: $(( $(wc -l) / 4 )) reads"
```
````

</TabItem>
</Tabs>

ðŸ“‚ **[Full Collection of Scripts](https://github.com/ISUgenomics/common_scripts)**

